{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "data = \"\"\"Introduction  \n",
        "The proposed Final Year Project aims to develop a smart retail services application where \n",
        "multiple retail store owners can register and upload their product details along with client \n",
        "transaction histories. The core objective of the app is to analyze transactional data using \n",
        "data mining techniques and recommend optimal product placement strategies to enhance \n",
        "sales and profitability. The app will employ database-driven algorithms such as the \n",
        "Apriori algorithm for association rule mining, helping to identify product bundles and \n",
        "customer buying patterns. \n",
        " \n",
        "Problem Statement \n",
        "Retail store owners often lack access to intelligent tools that help in understanding \n",
        "consumer buying behavior and optimizing product placement. As a result, they miss out \n",
        "on potential profits due to inefficient shelf organization and lack of product bundling \n",
        "strategies. There is a need for a platform that uses data analytics to provide actionable \n",
        "insights for boosting sales. \n",
        " \n",
        "Objectives \n",
        "• To allow retail stores to register and manage their product and transaction data. \n",
        "• To apply data mining algorithms (like Apriori) for discovering product associations. \n",
        "• To suggest optimal product placement strategies based on consumer purchasing \n",
        "behavior. \n",
        "• To increase overall sales and customer satisfaction through data-driven decision\n",
        "making. \n",
        " \n",
        "Key Features \n",
        "• Multi-store user registration and management system \n",
        "• Product catalog and transaction history upload \n",
        "• Association Rule Mining (Apriori Algorithm) \n",
        "• Recommendation engine for product placement \n",
        "• Dashboard for analytics and performance insights \n",
        " \n",
        " \n",
        " \n",
        " \n",
        "Technologies to Be Used \n",
        "• Frontend: React Native or Flutter (for cross-platform mobile app development) \n",
        "• Backend: Node.js with Express.js or Django (Python) \n",
        " \n",
        "3 | Page \n",
        " \n",
        "• Database: MongoDB or PostgreSQL (depending on schema flexibility) \n",
        "• Data Mining Libraries: \n",
        "o Python: mlxtend, pandas, scikit-learn \n",
        "o R (optional): arules, shiny \n",
        "• Cloud Hosting: Firebase, AWS, or Heroku \n",
        "• Data Visualization: Chart.js, D3.js, or Python Dash \n",
        " \n",
        "Database Algorithms to Be Used \n",
        "• Apriori Algorithm: For identifying frequent item sets and generating association \n",
        "rules to determine which products are often bought together. \n",
        "• FP-Growth Algorithm (Optional): As an alternative to Apriori for improved \n",
        "efficiency on large datasets. \n",
        "• Clustering Algorithms: To group similar customers or transaction types for further \n",
        "insights. \n",
        "• Recommendation System: Basic collaborative or content-based filtering for \n",
        "suggesting new products or placements. \n",
        " \n",
        "Expected Outcomes \n",
        "• An intelligent retail app capable of generating meaningful insights from store data. \n",
        "• A user-friendly interface for store managers to monitor performance and adopt \n",
        "suggested product placement. \n",
        "• Increased store sales through optimized strategies powered by data mining. \n",
        " \n",
        "Conclusion \n",
        "This project bridges the gap between retail management and data-driven \n",
        "decision-making. By leveraging database algorithms and modern mobile \n",
        "development frameworks, it provides a scalable solution for small to \n",
        "medium-sized retail businesses looking to enhance profitability through \n",
        "smarter analytics.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Reading the text file\n",
        "# file_path = r\"C:\\Users\\Adeel\\Desktop\\Deep Learning\\Deep_learning\\Next word.txt\"\n",
        "\n",
        "# # Open and read the file\n",
        "# with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#     data = file.read()\n",
        "\n",
        "# # Print the content of the file (optional)\n",
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "b8d7232a-c538-4f48-e331-aebea747c2c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "for sentence in data.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "cf7f38c7-9ebe-475e-e51c-dfee031c80f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[9, 71],\n",
              " [9, 71, 72],\n",
              " [9, 71, 72, 73],\n",
              " [9, 71, 72, 73, 32],\n",
              " [9, 71, 72, 73, 32, 74],\n",
              " [9, 71, 72, 73, 32, 74, 2],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10, 76],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10, 76, 8],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10, 76, 8, 77],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10, 76, 8, 77, 78],\n",
              " [9, 71, 72, 73, 32, 74, 2, 75, 10, 76, 8, 77, 78, 79],\n",
              " [80, 8],\n",
              " [80, 8, 11],\n",
              " [80, 8, 11, 33],\n",
              " [80, 8, 11, 33, 81],\n",
              " [80, 8, 11, 33, 81, 34],\n",
              " [80, 8, 11, 33, 81, 34, 3],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36, 5],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36, 5, 82],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36, 5, 82, 83],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36, 5, 82, 83, 37],\n",
              " [80, 8, 11, 33, 81, 34, 3, 35, 36, 5, 82, 83, 37, 84],\n",
              " [16, 85],\n",
              " [16, 85, 9],\n",
              " [16, 85, 9, 86],\n",
              " [16, 85, 9, 86, 87],\n",
              " [16, 85, 9, 86, 87, 25],\n",
              " [16, 85, 9, 86, 87, 25, 9],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38, 2],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38, 2, 88],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38, 2, 88, 89],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38, 2, 88, 89, 6],\n",
              " [16, 85, 9, 86, 87, 25, 9, 17, 38, 2, 88, 89, 6, 90],\n",
              " [6, 12],\n",
              " [6, 12, 91],\n",
              " [6, 12, 91, 3],\n",
              " [6, 12, 91, 3, 92],\n",
              " [6, 12, 91, 3, 92, 39],\n",
              " [6, 12, 91, 3, 92, 39, 5],\n",
              " [6, 12, 91, 3, 92, 39, 5, 13],\n",
              " [6, 12, 91, 3, 92, 39, 5, 13, 18],\n",
              " [6, 12, 91, 3, 92, 39, 5, 13, 18, 2],\n",
              " [6, 12, 91, 3, 92, 39, 5, 13, 18, 2, 40],\n",
              " [19, 3],\n",
              " [19, 3, 41],\n",
              " [19, 3, 41, 9],\n",
              " [19, 3, 41, 9, 17],\n",
              " [19, 3, 41, 9, 17, 93],\n",
              " [19, 3, 41, 9, 17, 93, 94],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20, 26],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20, 26, 14],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20, 26, 14, 95],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20, 26, 14, 95, 27],\n",
              " [19, 3, 41, 9, 17, 93, 94, 20, 26, 14, 95, 27, 9],\n",
              " [15, 21],\n",
              " [15, 21, 4],\n",
              " [15, 21, 4, 28],\n",
              " [15, 21, 4, 28, 42],\n",
              " [15, 21, 4, 28, 42, 12],\n",
              " [15, 21, 4, 28, 42, 12, 96],\n",
              " [15, 21, 4, 28, 42, 12, 96, 2],\n",
              " [15, 21, 4, 28, 42, 12, 96, 2, 97],\n",
              " [15, 21, 4, 28, 42, 12, 96, 2, 97, 5],\n",
              " [15, 21, 4, 28, 42, 12, 96, 2, 97, 5, 98],\n",
              " [15, 21, 4, 28, 42, 12, 96, 2, 97, 5, 98, 3],\n",
              " [43, 44],\n",
              " [43, 44, 99],\n",
              " [100, 101],\n",
              " [8, 11],\n",
              " [8, 11, 33],\n",
              " [8, 11, 33, 45],\n",
              " [8, 11, 33, 45, 46],\n",
              " [8, 11, 33, 45, 46, 102],\n",
              " [8, 11, 33, 45, 46, 102, 2],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47, 103],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47, 103, 48],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47, 103, 48, 104],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47, 103, 48, 104, 105],\n",
              " [8, 11, 33, 45, 46, 102, 2, 47, 103, 48, 104, 105, 106],\n",
              " [49, 44],\n",
              " [49, 44, 50],\n",
              " [49, 44, 50, 3],\n",
              " [49, 44, 50, 3, 107],\n",
              " [49, 44, 50, 3, 107, 5],\n",
              " [49, 44, 50, 3, 107, 5, 13],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27, 10],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27, 10, 108],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27, 10, 108, 109],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27, 10, 108, 109, 110],\n",
              " [49, 44, 50, 3, 107, 5, 13, 27, 10, 108, 109, 110, 111],\n",
              " [22, 112],\n",
              " [22, 112, 113],\n",
              " [22, 112, 113, 114],\n",
              " [22, 112, 113, 114, 2],\n",
              " [22, 112, 113, 114, 2, 115],\n",
              " [22, 112, 113, 114, 2, 115, 116],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117, 3],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117, 3, 46],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117, 3, 46, 25],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117, 3, 46, 25, 5],\n",
              " [22, 112, 113, 114, 2, 115, 116, 117, 3, 46, 25, 5, 118],\n",
              " [18, 119],\n",
              " [18, 119, 38],\n",
              " [18, 119, 38, 10],\n",
              " [18, 119, 38, 10, 120],\n",
              " [18, 119, 38, 10, 120, 4],\n",
              " [18, 119, 38, 10, 120, 4, 10],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121, 6],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121, 6, 29],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121, 6, 29, 2],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121, 6, 29, 2, 122],\n",
              " [18, 119, 38, 10, 120, 4, 10, 51, 48, 121, 6, 29, 2, 122, 123],\n",
              " [23, 4],\n",
              " [23, 4, 124],\n",
              " [23, 4, 124, 19],\n",
              " [1, 2],\n",
              " [1, 2, 126],\n",
              " [1, 2, 126, 8],\n",
              " [1, 2, 126, 8, 127],\n",
              " [1, 2, 126, 8, 127, 2],\n",
              " [1, 2, 126, 8, 127, 2, 34],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128, 36],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128, 36, 5],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128, 36, 5, 3],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128, 36, 5, 3, 16],\n",
              " [1, 2, 126, 8, 127, 2, 34, 3, 128, 36, 5, 3, 16, 6],\n",
              " [1, 2],\n",
              " [1, 2, 129],\n",
              " [1, 2, 129, 6],\n",
              " [1, 2, 129, 6, 12],\n",
              " [1, 2, 129, 6, 12, 14],\n",
              " [1, 2, 129, 6, 12, 14, 130],\n",
              " [1, 2, 129, 6, 12, 14, 130, 15],\n",
              " [1, 2, 129, 6, 12, 14, 130, 15, 4],\n",
              " [1, 2, 129, 6, 12, 14, 130, 15, 4, 131],\n",
              " [1, 2, 129, 6, 12, 14, 130, 15, 4, 131, 5],\n",
              " [1, 2, 129, 6, 12, 14, 130, 15, 4, 131, 5, 132],\n",
              " [1, 2],\n",
              " [1, 2, 133],\n",
              " [1, 2, 133, 39],\n",
              " [1, 2, 133, 39, 5],\n",
              " [1, 2, 133, 39, 5, 13],\n",
              " [1, 2, 133, 39, 5, 13, 18],\n",
              " [1, 2, 133, 39, 5, 13, 18, 52],\n",
              " [1, 2, 133, 39, 5, 13, 18, 52, 22],\n",
              " [1, 2, 133, 39, 5, 13, 18, 52, 22, 49],\n",
              " [1, 2, 133, 39, 5, 13, 18, 52, 22, 49, 134],\n",
              " [1, 2],\n",
              " [1, 2, 135],\n",
              " [1, 2, 135, 136],\n",
              " [1, 2, 135, 136, 19],\n",
              " [1, 2, 135, 136, 19, 3],\n",
              " [1, 2, 135, 136, 19, 3, 43],\n",
              " [1, 2, 135, 136, 19, 3, 43, 137],\n",
              " [1, 2, 135, 136, 19, 3, 43, 137, 30],\n",
              " [1, 2, 135, 136, 19, 3, 43, 137, 30, 6],\n",
              " [1, 2, 135, 136, 19, 3, 43, 137, 30, 6, 26],\n",
              " [1, 2, 135, 136, 19, 3, 43, 137, 30, 6, 26, 53],\n",
              " [138, 139],\n",
              " [1, 140],\n",
              " [1, 140, 11],\n",
              " [1, 140, 11, 55],\n",
              " [1, 140, 11, 55, 141],\n",
              " [1, 140, 11, 55, 141, 3],\n",
              " [1, 140, 11, 55, 141, 3, 56],\n",
              " [1, 140, 11, 55, 141, 3, 56, 57],\n",
              " [1, 5],\n",
              " [1, 5, 142],\n",
              " [1, 5, 142, 3],\n",
              " [1, 5, 142, 3, 16],\n",
              " [1, 5, 142, 3, 16, 143],\n",
              " [1, 5, 142, 3, 16, 143, 35],\n",
              " [1, 28],\n",
              " [1, 28, 42],\n",
              " [1, 28, 42, 12],\n",
              " [1, 28, 42, 12, 15],\n",
              " [1, 28, 42, 12, 15, 21],\n",
              " [1, 58],\n",
              " [1, 58, 144],\n",
              " [1, 58, 144, 4],\n",
              " [1, 58, 144, 4, 5],\n",
              " [1, 58, 144, 4, 5, 13],\n",
              " [1, 145],\n",
              " [1, 145, 4],\n",
              " [1, 145, 4, 29],\n",
              " [1, 145, 4, 29, 3],\n",
              " [1, 145, 4, 29, 3, 59],\n",
              " [1, 145, 4, 29, 3, 59, 23],\n",
              " [146, 2],\n",
              " [146, 2, 60],\n",
              " [146, 2, 60, 61],\n",
              " [1, 147],\n",
              " [1, 147, 148],\n",
              " [1, 147, 148, 149],\n",
              " [1, 147, 148, 149, 7],\n",
              " [1, 147, 148, 149, 7, 150],\n",
              " [1, 147, 148, 149, 7, 150, 4],\n",
              " [1, 147, 148, 149, 7, 150, 4, 151],\n",
              " [1, 147, 148, 149, 7, 150, 4, 151, 51],\n",
              " [1, 147, 148, 149, 7, 150, 4, 151, 51, 62],\n",
              " [1, 147, 148, 149, 7, 150, 4, 151, 51, 62, 17],\n",
              " [1, 147, 148, 149, 7, 150, 4, 151, 51, 62, 17, 63],\n",
              " [1, 152],\n",
              " [1, 152, 153],\n",
              " [1, 152, 153, 24],\n",
              " [1, 152, 153, 24, 37],\n",
              " [1, 152, 153, 24, 37, 154],\n",
              " [1, 152, 153, 24, 37, 154, 24],\n",
              " [1, 152, 153, 24, 37, 154, 24, 7],\n",
              " [1, 152, 153, 24, 37, 154, 24, 7, 155],\n",
              " [1, 152, 153, 24, 37, 154, 24, 7, 155, 31],\n",
              " [156, 157],\n",
              " [1, 20],\n",
              " [1, 20, 158],\n",
              " [1, 20, 158, 7],\n",
              " [1, 20, 158, 7, 159],\n",
              " [1, 20, 158, 7, 159, 160],\n",
              " [1, 20, 158, 7, 159, 160, 22],\n",
              " [1, 20, 158, 7, 159, 160, 22, 161],\n",
              " [1, 20, 158, 7, 159, 160, 22, 161, 162],\n",
              " [1, 6],\n",
              " [1, 6, 12],\n",
              " [1, 6, 12, 163],\n",
              " [64, 31],\n",
              " [64, 31, 164],\n",
              " [64, 31, 164, 165],\n",
              " [64, 31, 164, 165, 166],\n",
              " [64, 31, 164, 165, 166, 167],\n",
              " [64, 168],\n",
              " [64, 168, 65],\n",
              " [64, 168, 65, 169],\n",
              " [64, 168, 65, 169, 170],\n",
              " [1, 171],\n",
              " [1, 171, 172],\n",
              " [1, 171, 172, 173],\n",
              " [1, 171, 172, 173, 174],\n",
              " [1, 171, 172, 173, 174, 7],\n",
              " [1, 171, 172, 173, 174, 7, 175],\n",
              " [1, 6],\n",
              " [1, 6, 176],\n",
              " [1, 6, 176, 177],\n",
              " [1, 6, 176, 177, 24],\n",
              " [1, 6, 176, 177, 24, 178],\n",
              " [1, 6, 176, 177, 24, 178, 24],\n",
              " [1, 6, 176, 177, 24, 178, 24, 7],\n",
              " [1, 6, 176, 177, 24, 178, 24, 7, 31],\n",
              " [1, 6, 176, 177, 24, 178, 24, 7, 31, 179],\n",
              " [20, 14],\n",
              " [20, 14, 2],\n",
              " [20, 14, 2, 60],\n",
              " [20, 14, 2, 60, 61],\n",
              " [1, 15],\n",
              " [1, 15, 21],\n",
              " [1, 15, 21, 4],\n",
              " [1, 15, 21, 4, 180],\n",
              " [1, 15, 21, 4, 180, 181],\n",
              " [1, 15, 21, 4, 180, 181, 182],\n",
              " [1, 15, 21, 4, 180, 181, 182, 183],\n",
              " [1, 15, 21, 4, 180, 181, 182, 183, 3],\n",
              " [1, 15, 21, 4, 180, 181, 182, 183, 3, 66],\n",
              " [1, 15, 21, 4, 180, 181, 182, 183, 3, 66, 28],\n",
              " [184, 2],\n",
              " [184, 2, 185],\n",
              " [184, 2, 185, 186],\n",
              " [184, 2, 185, 186, 67],\n",
              " [184, 2, 185, 186, 67, 187],\n",
              " [184, 2, 185, 186, 67, 187, 45],\n",
              " [184, 2, 185, 186, 67, 187, 45, 188],\n",
              " [184, 2, 185, 186, 67, 187, 45, 188, 189],\n",
              " [1, 190],\n",
              " [1, 190, 191],\n",
              " [1, 190, 191, 21],\n",
              " [1, 190, 191, 21, 65],\n",
              " [1, 190, 191, 21, 65, 27],\n",
              " [1, 190, 191, 21, 65, 27, 68],\n",
              " [1, 190, 191, 21, 65, 27, 68, 192],\n",
              " [1, 190, 191, 21, 65, 27, 68, 192, 2],\n",
              " [1, 190, 191, 21, 65, 27, 68, 192, 2, 15],\n",
              " [1, 190, 191, 21, 65, 27, 68, 192, 2, 15, 4],\n",
              " [1, 190, 191, 21, 65, 27, 68, 192, 2, 15, 4, 193],\n",
              " [194, 22],\n",
              " [194, 22, 195],\n",
              " [194, 22, 195, 196],\n",
              " [1, 197],\n",
              " [1, 197, 14],\n",
              " [1, 197, 14, 2],\n",
              " [1, 197, 14, 2, 198],\n",
              " [1, 197, 14, 2, 198, 199],\n",
              " [1, 197, 14, 2, 198, 199, 200],\n",
              " [1, 197, 14, 2, 198, 199, 200, 7],\n",
              " [1, 197, 14, 2, 198, 199, 200, 7, 16],\n",
              " [1, 197, 14, 2, 198, 199, 200, 7, 16, 201],\n",
              " [1, 197, 14, 2, 198, 199, 200, 7, 16, 201, 4],\n",
              " [1, 197, 14, 2, 198, 199, 200, 7, 16, 201, 4, 202],\n",
              " [1, 58],\n",
              " [1, 58, 57],\n",
              " [1, 58, 57, 203],\n",
              " [1, 58, 57, 203, 204],\n",
              " [1, 58, 57, 203, 204, 7],\n",
              " [1, 58, 57, 203, 204, 7, 205],\n",
              " [1, 58, 57, 203, 204, 7, 205, 52],\n",
              " [1, 58, 57, 203, 204, 7, 205, 52, 206],\n",
              " [1, 58, 57, 203, 204, 7, 205, 52, 206, 4],\n",
              " [207, 208],\n",
              " [207, 208, 67],\n",
              " [207, 208, 67, 7],\n",
              " [207, 208, 67, 7, 209],\n",
              " [210, 211],\n",
              " [1, 68],\n",
              " [1, 68, 47],\n",
              " [1, 68, 47, 8],\n",
              " [1, 68, 47, 8, 17],\n",
              " [1, 68, 47, 8, 17, 212],\n",
              " [1, 68, 47, 8, 17, 212, 25],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66, 213],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66, 213, 23],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66, 213, 23, 214],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66, 213, 23, 214, 11],\n",
              " [1, 68, 47, 8, 17, 212, 25, 66, 213, 23, 214, 11, 6],\n",
              " [1, 10],\n",
              " [1, 10, 55],\n",
              " [1, 10, 55, 215],\n",
              " [1, 10, 55, 215, 216],\n",
              " [1, 10, 55, 215, 216, 4],\n",
              " [1, 10, 55, 215, 216, 4, 11],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217, 2],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217, 2, 218],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217, 2, 218, 59],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217, 2, 218, 59, 3],\n",
              " [1, 10, 55, 215, 216, 4, 11, 217, 2, 218, 59, 3, 219],\n",
              " [220, 5],\n",
              " [220, 5, 13],\n",
              " [1, 221],\n",
              " [1, 221, 11],\n",
              " [1, 221, 11, 19],\n",
              " [1, 221, 11, 19, 30],\n",
              " [1, 221, 11, 19, 30, 222],\n",
              " [1, 221, 11, 19, 30, 222, 18],\n",
              " [1, 221, 11, 19, 30, 222, 18, 223],\n",
              " [1, 221, 11, 19, 30, 222, 18, 223, 69],\n",
              " [1, 221, 11, 19, 30, 222, 18, 223, 69, 6],\n",
              " [1, 221, 11, 19, 30, 222, 18, 223, 69, 6, 12],\n",
              " [225, 32],\n",
              " [225, 32, 226],\n",
              " [225, 32, 226, 9],\n",
              " [225, 32, 226, 9, 227],\n",
              " [225, 32, 226, 9, 227, 228],\n",
              " [225, 32, 226, 9, 227, 228, 8],\n",
              " [225, 32, 226, 9, 227, 228, 8, 56],\n",
              " [225, 32, 226, 9, 227, 228, 8, 56, 3],\n",
              " [225, 32, 226, 9, 227, 228, 8, 56, 3, 6],\n",
              " [225, 32, 226, 9, 227, 228, 8, 56, 3, 6, 26],\n",
              " [53, 54],\n",
              " [53, 54, 69],\n",
              " [53, 54, 69, 229],\n",
              " [53, 54, 69, 229, 20],\n",
              " [53, 54, 69, 229, 20, 14],\n",
              " [53, 54, 69, 229, 20, 14, 3],\n",
              " [53, 54, 69, 229, 20, 14, 3, 230],\n",
              " [53, 54, 69, 229, 20, 14, 3, 230, 62],\n",
              " [63, 231],\n",
              " [63, 231, 232],\n",
              " [63, 231, 232, 233],\n",
              " [63, 231, 232, 233, 10],\n",
              " [63, 231, 232, 233, 10, 234],\n",
              " [63, 231, 232, 233, 10, 234, 235],\n",
              " [63, 231, 232, 233, 10, 234, 235, 4],\n",
              " [63, 231, 232, 233, 10, 234, 235, 4, 236],\n",
              " [63, 231, 232, 233, 10, 234, 235, 4, 236, 2],\n",
              " [237, 238],\n",
              " [237, 238, 8],\n",
              " [237, 238, 8, 239],\n",
              " [237, 238, 8, 239, 240],\n",
              " [237, 238, 8, 239, 240, 2],\n",
              " [237, 238, 8, 239, 240, 2, 40],\n",
              " [237, 238, 8, 239, 240, 2, 40, 41],\n",
              " [237, 238, 8, 239, 240, 2, 40, 41, 30],\n",
              " [241, 29]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "e1d10078-2877-40eb-aebd-f5a74656d0b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   9,  71],\n",
              "       [  0,   0,   0, ...,   9,  71,  72],\n",
              "       [  0,   0,   0, ...,  71,  72,  73],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   2,  40,  41],\n",
              "       [  0,   0,   0, ...,  40,  41,  30],\n",
              "       [  0,   0,   0, ...,   0, 241,  29]], dtype=int32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "outputs": [],
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0   0   9]\n",
            " [  0   0   0 ...   0   9  71]\n",
            " [  0   0   0 ...   9  71  72]\n",
            " ...\n",
            " [  0   0   0 ... 240   2  40]\n",
            " [  0   0   0 ...   2  40  41]\n",
            " [  0   0   0 ...   0   0 241]]\n",
            "(395, 14)\n"
          ]
        }
      ],
      "source": [
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "outputs": [],
      "source": [
        "y = padded_input_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "726091f2-6d5e-408e-aa32-fafa30583879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 71,  72,  73,  32,  74,   2,  75,  10,  76,   8,  77,  78,  79,\n",
              "         8,  11,  33,  81,  34,   3,  35,  36,   5,  82,  83,  37,  84,\n",
              "        85,   9,  86,  87,  25,   9,  17,  38,   2,  88,  89,   6,  90,\n",
              "        12,  91,   3,  92,  39,   5,  13,  18,   2,  40,   3,  41,   9,\n",
              "        17,  93,  94,  20,  26,  14,  95,  27,   9,  21,   4,  28,  42,\n",
              "        12,  96,   2,  97,   5,  98,   3,  44,  99, 101,  11,  33,  45,\n",
              "        46, 102,   2,  47, 103,  48, 104, 105, 106,  44,  50,   3, 107,\n",
              "         5,  13,  27,  10, 108, 109, 110, 111, 112, 113, 114,   2, 115,\n",
              "       116, 117,   3,  46,  25,   5, 118, 119,  38,  10, 120,   4,  10,\n",
              "        51,  48, 121,   6,  29,   2, 122, 123,   4, 124,  19,   2, 126,\n",
              "         8, 127,   2,  34,   3, 128,  36,   5,   3,  16,   6,   2, 129,\n",
              "         6,  12,  14, 130,  15,   4, 131,   5, 132,   2, 133,  39,   5,\n",
              "        13,  18,  52,  22,  49, 134,   2, 135, 136,  19,   3,  43, 137,\n",
              "        30,   6,  26,  53, 139, 140,  11,  55, 141,   3,  56,  57,   5,\n",
              "       142,   3,  16, 143,  35,  28,  42,  12,  15,  21,  58, 144,   4,\n",
              "         5,  13, 145,   4,  29,   3,  59,  23,   2,  60,  61, 147, 148,\n",
              "       149,   7, 150,   4, 151,  51,  62,  17,  63, 152, 153,  24,  37,\n",
              "       154,  24,   7, 155,  31, 157,  20, 158,   7, 159, 160,  22, 161,\n",
              "       162,   6,  12, 163,  31, 164, 165, 166, 167, 168,  65, 169, 170,\n",
              "       171, 172, 173, 174,   7, 175,   6, 176, 177,  24, 178,  24,   7,\n",
              "        31, 179,  14,   2,  60,  61,  15,  21,   4, 180, 181, 182, 183,\n",
              "         3,  66,  28,   2, 185, 186,  67, 187,  45, 188, 189, 190, 191,\n",
              "        21,  65,  27,  68, 192,   2,  15,   4, 193,  22, 195, 196, 197,\n",
              "        14,   2, 198, 199, 200,   7,  16, 201,   4, 202,  58,  57, 203,\n",
              "       204,   7, 205,  52, 206,   4, 208,  67,   7, 209, 211,  68,  47,\n",
              "         8,  17, 212,  25,  66, 213,  23, 214,  11,   6,  10,  55, 215,\n",
              "       216,   4,  11, 217,   2, 218,  59,   3, 219,   5,  13, 221,  11,\n",
              "        19,  30, 222,  18, 223,  69,   6,  12,  32, 226,   9, 227, 228,\n",
              "         8,  56,   3,   6,  26,  54,  69, 229,  20,  14,   3, 230,  62,\n",
              "       231, 232, 233,  10, 234, 235,   4, 236,   2, 238,   8, 239, 240,\n",
              "         2,  40,  41,  30,  29], dtype=int32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "87e67e59-511d-4803-c1d8-383fdbd9dea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(395,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.word_index) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=242)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "c5a0bfee-e63f-4d04-fdc0-d9a64c314804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(395, 242)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo-OYfHpTK2o",
        "outputId": "a135eea2-37b4-4427-ca78-79c9af481c1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Adeel\\Desktop\\Deep Learning\\Deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,542</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m24,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m180,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m242\u001b[0m)            │        \u001b[38;5;34m36,542\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">391,942</span> (1.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m391,942\u001b[0m (1.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">391,942</span> (1.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m391,942\u001b[0m (1.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=242, output_dim=100, input_length=X.shape[1]))  # Embedding layer\n",
        "model.add(LSTM(150, return_sequences=True))  # First LSTM layer\n",
        "model.add(LSTM(150))  # Second LSTM layer\n",
        "model.add(Dense(242, activation='softmax'))  # Output layer\n",
        "model.build(input_shape=(None, X.shape[1]))  # Build the model with input shape\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-GGjqh7ue_Yq"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - accuracy: 0.0104 - loss: 5.4826 - val_accuracy: 0.0380 - val_loss: 5.4478\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.0453 - loss: 5.2919 - val_accuracy: 0.0380 - val_loss: 5.5542\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0329 - loss: 5.2106 - val_accuracy: 0.0380 - val_loss: 5.6730\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0468 - loss: 4.9986 - val_accuracy: 0.0380 - val_loss: 5.8924\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0754 - loss: 4.8931 - val_accuracy: 0.0380 - val_loss: 6.0443\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0659 - loss: 4.9528 - val_accuracy: 0.0380 - val_loss: 6.0837\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0468 - loss: 4.8646 - val_accuracy: 0.0380 - val_loss: 6.2278\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.0612 - loss: 4.8955 - val_accuracy: 0.0380 - val_loss: 6.3281\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0471 - loss: 4.8518 - val_accuracy: 0.0253 - val_loss: 6.4334\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0614 - loss: 4.7669 - val_accuracy: 0.0253 - val_loss: 6.5129\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0607 - loss: 4.7578 - val_accuracy: 0.0506 - val_loss: 6.5523\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0626 - loss: 4.6115 - val_accuracy: 0.0253 - val_loss: 6.6214\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0634 - loss: 4.5594 - val_accuracy: 0.0506 - val_loss: 6.7003\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0802 - loss: 4.4974 - val_accuracy: 0.0380 - val_loss: 6.7526\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0745 - loss: 4.4301 - val_accuracy: 0.0380 - val_loss: 6.8926\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0895 - loss: 4.3336 - val_accuracy: 0.0380 - val_loss: 6.9623\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0692 - loss: 4.3673 - val_accuracy: 0.0253 - val_loss: 6.9971\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0948 - loss: 4.2016 - val_accuracy: 0.0380 - val_loss: 7.0168\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0926 - loss: 4.1440 - val_accuracy: 0.0380 - val_loss: 7.1298\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0925 - loss: 4.1065 - val_accuracy: 0.0127 - val_loss: 7.1807\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1095 - loss: 3.9883 - val_accuracy: 0.0380 - val_loss: 7.2456\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0995 - loss: 3.9815 - val_accuracy: 0.0380 - val_loss: 7.2739\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1306 - loss: 3.8604 - val_accuracy: 0.0380 - val_loss: 7.3357\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0958 - loss: 3.9346 - val_accuracy: 0.0380 - val_loss: 7.3570\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0939 - loss: 3.8337 - val_accuracy: 0.0253 - val_loss: 7.3360\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1444 - loss: 3.7411 - val_accuracy: 0.0506 - val_loss: 7.4380\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1263 - loss: 3.7055 - val_accuracy: 0.0380 - val_loss: 7.4960\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1238 - loss: 3.6676 - val_accuracy: 0.0253 - val_loss: 7.4996\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1643 - loss: 3.5421 - val_accuracy: 0.0253 - val_loss: 7.5155\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1853 - loss: 3.5695 - val_accuracy: 0.0253 - val_loss: 7.5749\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1772 - loss: 3.4494 - val_accuracy: 0.0253 - val_loss: 7.6456\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1763 - loss: 3.5059 - val_accuracy: 0.0380 - val_loss: 7.6718\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1691 - loss: 3.4158 - val_accuracy: 0.0253 - val_loss: 7.7575\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2308 - loss: 3.2813 - val_accuracy: 0.0253 - val_loss: 7.7428\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1817 - loss: 3.3765 - val_accuracy: 0.0253 - val_loss: 7.7769\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1956 - loss: 3.2813 - val_accuracy: 0.0253 - val_loss: 7.7519\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2065 - loss: 3.2147 - val_accuracy: 0.0380 - val_loss: 7.8480\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2517 - loss: 3.1802 - val_accuracy: 0.0380 - val_loss: 7.8788\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2520 - loss: 3.1053 - val_accuracy: 0.0380 - val_loss: 7.9203\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2610 - loss: 2.9868 - val_accuracy: 0.0253 - val_loss: 7.9327\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2479 - loss: 3.0540 - val_accuracy: 0.0506 - val_loss: 8.0151\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3025 - loss: 2.9733 - val_accuracy: 0.0380 - val_loss: 7.9897\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3170 - loss: 2.8848 - val_accuracy: 0.0380 - val_loss: 8.0574\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3263 - loss: 2.8710 - val_accuracy: 0.0380 - val_loss: 8.0567\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3184 - loss: 2.8555 - val_accuracy: 0.0506 - val_loss: 8.0632\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3670 - loss: 2.6910 - val_accuracy: 0.0380 - val_loss: 8.1487\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3573 - loss: 2.7241 - val_accuracy: 0.0380 - val_loss: 8.1037\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3721 - loss: 2.6990 - val_accuracy: 0.0380 - val_loss: 8.1565\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3893 - loss: 2.5566 - val_accuracy: 0.0506 - val_loss: 8.1650\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.3793 - loss: 2.6185 - val_accuracy: 0.0380 - val_loss: 8.2052\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3994 - loss: 2.5298 - val_accuracy: 0.0253 - val_loss: 8.1879\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4024 - loss: 2.4776 - val_accuracy: 0.0253 - val_loss: 8.2470\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4269 - loss: 2.4032 - val_accuracy: 0.0253 - val_loss: 8.2988\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4669 - loss: 2.4046 - val_accuracy: 0.0380 - val_loss: 8.3459\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4683 - loss: 2.3030 - val_accuracy: 0.0253 - val_loss: 8.3492\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4644 - loss: 2.3340 - val_accuracy: 0.0380 - val_loss: 8.3106\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5437 - loss: 2.2065 - val_accuracy: 0.0253 - val_loss: 8.3519\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5086 - loss: 2.2509 - val_accuracy: 0.0253 - val_loss: 8.3966\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5353 - loss: 2.1688 - val_accuracy: 0.0253 - val_loss: 8.4182\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5379 - loss: 2.0933 - val_accuracy: 0.0380 - val_loss: 8.4415\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5286 - loss: 2.1280 - val_accuracy: 0.0253 - val_loss: 8.4641\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5650 - loss: 2.0312 - val_accuracy: 0.0380 - val_loss: 8.4925\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5965 - loss: 1.9706 - val_accuracy: 0.0380 - val_loss: 8.5215\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5862 - loss: 1.9671 - val_accuracy: 0.0380 - val_loss: 8.5230\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5825 - loss: 1.9604 - val_accuracy: 0.0253 - val_loss: 8.5984\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6297 - loss: 1.9156 - val_accuracy: 0.0253 - val_loss: 8.6037\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6698 - loss: 1.7664 - val_accuracy: 0.0253 - val_loss: 8.5918\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6336 - loss: 1.8194 - val_accuracy: 0.0380 - val_loss: 8.6652\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6584 - loss: 1.7720 - val_accuracy: 0.0253 - val_loss: 8.6497\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6799 - loss: 1.7140 - val_accuracy: 0.0253 - val_loss: 8.6979\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6504 - loss: 1.7563 - val_accuracy: 0.0380 - val_loss: 8.7238\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6829 - loss: 1.7371 - val_accuracy: 0.0380 - val_loss: 8.7821\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7262 - loss: 1.5738 - val_accuracy: 0.0253 - val_loss: 8.7445\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7060 - loss: 1.5565 - val_accuracy: 0.0380 - val_loss: 8.8256\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7312 - loss: 1.4897 - val_accuracy: 0.0380 - val_loss: 8.8019\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7347 - loss: 1.4703 - val_accuracy: 0.0253 - val_loss: 8.8373\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7563 - loss: 1.4604 - val_accuracy: 0.0380 - val_loss: 8.8767\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7860 - loss: 1.3687 - val_accuracy: 0.0253 - val_loss: 8.9041\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7356 - loss: 1.4787 - val_accuracy: 0.0380 - val_loss: 8.9447\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7432 - loss: 1.3953 - val_accuracy: 0.0506 - val_loss: 8.9249\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7648 - loss: 1.3303 - val_accuracy: 0.0253 - val_loss: 8.9614\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7669 - loss: 1.3728 - val_accuracy: 0.0380 - val_loss: 9.0333\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7538 - loss: 1.2981 - val_accuracy: 0.0506 - val_loss: 9.0462\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7891 - loss: 1.2333 - val_accuracy: 0.0253 - val_loss: 9.0376\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7895 - loss: 1.2134 - val_accuracy: 0.0380 - val_loss: 9.0678\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8073 - loss: 1.1640 - val_accuracy: 0.0506 - val_loss: 9.1143\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7901 - loss: 1.1913 - val_accuracy: 0.0253 - val_loss: 9.1021\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7649 - loss: 1.2040 - val_accuracy: 0.0253 - val_loss: 9.1621\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8161 - loss: 1.1039 - val_accuracy: 0.0380 - val_loss: 9.1745\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7969 - loss: 1.1002 - val_accuracy: 0.0127 - val_loss: 9.1999\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7987 - loss: 1.1368 - val_accuracy: 0.0380 - val_loss: 9.1811\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8230 - loss: 1.0342 - val_accuracy: 0.0253 - val_loss: 9.2537\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7929 - loss: 1.0935 - val_accuracy: 0.0253 - val_loss: 9.2459\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7946 - loss: 1.0942 - val_accuracy: 0.0253 - val_loss: 9.2675\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8175 - loss: 1.0521 - val_accuracy: 0.0253 - val_loss: 9.2946\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8192 - loss: 1.0543 - val_accuracy: 0.0127 - val_loss: 9.3166\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8581 - loss: 0.9309 - val_accuracy: 0.0253 - val_loss: 9.3541\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8562 - loss: 0.8910 - val_accuracy: 0.0253 - val_loss: 9.3407\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8491 - loss: 0.9365 - val_accuracy: 0.0253 - val_loss: 9.3769\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8288 - loss: 0.9441 - val_accuracy: 0.0253 - val_loss: 9.4110\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2789f514cd0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X, y, epochs=100,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
            "retail store owners\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "retail store owners often\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "retail store owners often lack\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "retail store owners often lack access\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "retail store owners often lack access to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "retail store owners often lack access to intelligent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "retail store owners often lack access to intelligent intelligent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "retail store owners often lack access to intelligent intelligent tools\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "retail store owners often lack access to intelligent intelligent tools that\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "retail store owners often lack access to intelligent intelligent tools that help\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "text = \"retail store\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=15, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxsj-_CjbQW",
        "outputId": "7e8e0b43-d8f5-4e87-8caf-33806965ab3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'•': 1,\n",
              " 'to': 2,\n",
              " 'and': 3,\n",
              " 'for': 4,\n",
              " 'product': 5,\n",
              " 'data': 6,\n",
              " 'or': 7,\n",
              " 'retail': 8,\n",
              " 'the': 9,\n",
              " 'a': 10,\n",
              " 'store': 11,\n",
              " 'mining': 12,\n",
              " 'placement': 13,\n",
              " 'algorithms': 14,\n",
              " 'apriori': 15,\n",
              " 'transaction': 16,\n",
              " 'app': 17,\n",
              " 'strategies': 18,\n",
              " 'sales': 19,\n",
              " 'database': 20,\n",
              " 'algorithm': 21,\n",
              " 'on': 22,\n",
              " 'insights': 23,\n",
              " 'js': 24,\n",
              " 'of': 25,\n",
              " 'driven': 26,\n",
              " 'as': 27,\n",
              " 'association': 28,\n",
              " 'analytics': 29,\n",
              " 'through': 30,\n",
              " 'python': 31,\n",
              " 'project': 32,\n",
              " 'owners': 33,\n",
              " 'register': 34,\n",
              " 'upload': 35,\n",
              " 'their': 36,\n",
              " 'with': 37,\n",
              " 'is': 38,\n",
              " 'optimal': 39,\n",
              " 'enhance': 40,\n",
              " 'profitability': 41,\n",
              " 'rule': 42,\n",
              " 'customer': 43,\n",
              " 'buying': 44,\n",
              " 'often': 45,\n",
              " 'lack': 46,\n",
              " 'intelligent': 47,\n",
              " 'that': 48,\n",
              " 'consumer': 49,\n",
              " 'behavior': 50,\n",
              " 'platform': 51,\n",
              " 'based': 52,\n",
              " 'decision': 53,\n",
              " 'making': 54,\n",
              " 'user': 55,\n",
              " 'management': 56,\n",
              " 'system': 57,\n",
              " 'recommendation': 58,\n",
              " 'performance': 59,\n",
              " 'be': 60,\n",
              " 'used': 61,\n",
              " 'mobile': 62,\n",
              " 'development': 63,\n",
              " 'o': 64,\n",
              " 'optional': 65,\n",
              " 'generating': 66,\n",
              " 'products': 67,\n",
              " 'an': 68,\n",
              " 'by': 69,\n",
              " 'introduction': 70,\n",
              " 'proposed': 71,\n",
              " 'final': 72,\n",
              " 'year': 73,\n",
              " 'aims': 74,\n",
              " 'develop': 75,\n",
              " 'smart': 76,\n",
              " 'services': 77,\n",
              " 'application': 78,\n",
              " 'where': 79,\n",
              " 'multiple': 80,\n",
              " 'can': 81,\n",
              " 'details': 82,\n",
              " 'along': 83,\n",
              " 'client': 84,\n",
              " 'histories': 85,\n",
              " 'core': 86,\n",
              " 'objective': 87,\n",
              " 'analyze': 88,\n",
              " 'transactional': 89,\n",
              " 'using': 90,\n",
              " 'techniques': 91,\n",
              " 'recommend': 92,\n",
              " 'will': 93,\n",
              " 'employ': 94,\n",
              " 'such': 95,\n",
              " 'helping': 96,\n",
              " 'identify': 97,\n",
              " 'bundles': 98,\n",
              " 'patterns': 99,\n",
              " 'problem': 100,\n",
              " 'statement': 101,\n",
              " 'access': 102,\n",
              " 'tools': 103,\n",
              " 'help': 104,\n",
              " 'in': 105,\n",
              " 'understanding': 106,\n",
              " 'optimizing': 107,\n",
              " 'result': 108,\n",
              " 'they': 109,\n",
              " 'miss': 110,\n",
              " 'out': 111,\n",
              " 'potential': 112,\n",
              " 'profits': 113,\n",
              " 'due': 114,\n",
              " 'inefficient': 115,\n",
              " 'shelf': 116,\n",
              " 'organization': 117,\n",
              " 'bundling': 118,\n",
              " 'there': 119,\n",
              " 'need': 120,\n",
              " 'uses': 121,\n",
              " 'provide': 122,\n",
              " 'actionable': 123,\n",
              " 'boosting': 124,\n",
              " 'objectives': 125,\n",
              " 'allow': 126,\n",
              " 'stores': 127,\n",
              " 'manage': 128,\n",
              " 'apply': 129,\n",
              " 'like': 130,\n",
              " 'discovering': 131,\n",
              " 'associations': 132,\n",
              " 'suggest': 133,\n",
              " 'purchasing': 134,\n",
              " 'increase': 135,\n",
              " 'overall': 136,\n",
              " 'satisfaction': 137,\n",
              " 'key': 138,\n",
              " 'features': 139,\n",
              " 'multi': 140,\n",
              " 'registration': 141,\n",
              " 'catalog': 142,\n",
              " 'history': 143,\n",
              " 'engine': 144,\n",
              " 'dashboard': 145,\n",
              " 'technologies': 146,\n",
              " 'frontend': 147,\n",
              " 'react': 148,\n",
              " 'native': 149,\n",
              " 'flutter': 150,\n",
              " 'cross': 151,\n",
              " 'backend': 152,\n",
              " 'node': 153,\n",
              " 'express': 154,\n",
              " 'django': 155,\n",
              " '3': 156,\n",
              " 'page': 157,\n",
              " 'mongodb': 158,\n",
              " 'postgresql': 159,\n",
              " 'depending': 160,\n",
              " 'schema': 161,\n",
              " 'flexibility': 162,\n",
              " 'libraries': 163,\n",
              " 'mlxtend': 164,\n",
              " 'pandas': 165,\n",
              " 'scikit': 166,\n",
              " 'learn': 167,\n",
              " 'r': 168,\n",
              " 'arules': 169,\n",
              " 'shiny': 170,\n",
              " 'cloud': 171,\n",
              " 'hosting': 172,\n",
              " 'firebase': 173,\n",
              " 'aws': 174,\n",
              " 'heroku': 175,\n",
              " 'visualization': 176,\n",
              " 'chart': 177,\n",
              " 'd3': 178,\n",
              " 'dash': 179,\n",
              " 'identifying': 180,\n",
              " 'frequent': 181,\n",
              " 'item': 182,\n",
              " 'sets': 183,\n",
              " 'rules': 184,\n",
              " 'determine': 185,\n",
              " 'which': 186,\n",
              " 'are': 187,\n",
              " 'bought': 188,\n",
              " 'together': 189,\n",
              " 'fp': 190,\n",
              " 'growth': 191,\n",
              " 'alternative': 192,\n",
              " 'improved': 193,\n",
              " 'efficiency': 194,\n",
              " 'large': 195,\n",
              " 'datasets': 196,\n",
              " 'clustering': 197,\n",
              " 'group': 198,\n",
              " 'similar': 199,\n",
              " 'customers': 200,\n",
              " 'types': 201,\n",
              " 'further': 202,\n",
              " 'basic': 203,\n",
              " 'collaborative': 204,\n",
              " 'content': 205,\n",
              " 'filtering': 206,\n",
              " 'suggesting': 207,\n",
              " 'new': 208,\n",
              " 'placements': 209,\n",
              " 'expected': 210,\n",
              " 'outcomes': 211,\n",
              " 'capable': 212,\n",
              " 'meaningful': 213,\n",
              " 'from': 214,\n",
              " 'friendly': 215,\n",
              " 'interface': 216,\n",
              " 'managers': 217,\n",
              " 'monitor': 218,\n",
              " 'adopt': 219,\n",
              " 'suggested': 220,\n",
              " 'increased': 221,\n",
              " 'optimized': 222,\n",
              " 'powered': 223,\n",
              " 'conclusion': 224,\n",
              " 'this': 225,\n",
              " 'bridges': 226,\n",
              " 'gap': 227,\n",
              " 'between': 228,\n",
              " 'leveraging': 229,\n",
              " 'modern': 230,\n",
              " 'frameworks': 231,\n",
              " 'it': 232,\n",
              " 'provides': 233,\n",
              " 'scalable': 234,\n",
              " 'solution': 235,\n",
              " 'small': 236,\n",
              " 'medium': 237,\n",
              " 'sized': 238,\n",
              " 'businesses': 239,\n",
              " 'looking': 240,\n",
              " 'smarter': 241}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
