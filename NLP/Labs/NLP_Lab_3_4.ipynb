{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S5RieHx-fbsB"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15528,"status":"ok","timestamp":1741064128655,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"D7rcqkrIgZxj","outputId":"eacd0ff1-51d2-40ad-8791-ed16b78f8345"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1741064434731,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"oALcX5IXglKC","outputId":"ecac63a7-56f2-4347-ede1-6140cf4e6f6c"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Adeel Naeem \n","          Al-Awan Town New Chakra Rawalpindi \n","                          +92-316-5659775 \n","adeeln454@gmail.com, https://www.linkedin.com/in/adeel-naeem-952108267,  https://github.com/AdeelNaeem44                                 \n"," \n"," \n"," \n","Seeking a Data Science Fellowship position to apply and enhance my skills in Programming Languages \n"," \n","EXPERIENCE  \n","Fresher \n","                      \n","EDUCATION  \n","2022-BEYOND  \n","BSAI, NUML ISLAMABAD  \n","I’m doing Bachelor’s in AI and currently in 5th semester.  \n","  \n","2020-2022  \n","INTERMEDIATE, PUNJAB GROUP OF COLLEGES   \n","I passed my intermediate degree in FSC subjects with a grade ‘A+’.  \n","  \n"," \n","SKILLS  \n"," \n","• \n","SQL  \n","  \n","• \n","Python  \n","• \n","C++  \n","• \n","Java \n"," \n","ACTIVITIES  \n","Myself Adeel Naeem. A Bachelor's student passionate about AI. Currently, I am a Student in Nation \n","University of Modern Languages but now I want to move on some modern tech. So I choose Data \n","Science as it’s also related with AI. In extra time, I play E-Games & cricket.  \n","\n"]}],"source":["\n","import fitz\n","\n","file_path='/content/drive/MyDrive/Adeel_resume.pdf'\n","def extract_text_from_pdf(file_path):\n","  doc=fitz.open(file_path)\n","  text=''\n","  for page in doc:\n","    text+=page.get_text()\n","  return text\n","text=extract_text_from_pdf(file_path)\n","print(text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1741065049336,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"faN8HH02hxga","outputId":"d4906543-215f-434f-87e8-9c945ca5ec88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello world\n","sample\n","13\n","['This', 'is', 'a', 'sentence.']\n","This is a sentence.\n"]}],"source":["str1 = \"Hello\"\n","str2 = \"world\"\n","result = str1 + \" \" + str2\n","print(result)\n","\n","#Substring: Extracting a part of a string.\n","text = \"This is a sample text.\"\n","substring = text[10:16]\n","print(substring)\n","\n","#Length: Getting the length of a string.\n","text = \"Hello, world!\"\n","length = len(text)\n","print(length)\n","\n","#Splitting: Splitting a string into a list of substrings.\n","text = \"This is a sentence.\"\n","words = text.split()\n","print(words)\n","\n","#Joining: Joining a list of strings into a single string.\n","words = ['This', 'is', 'a', 'sentence.']\n","text = ' '.join(words)\n","print(text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1741065504500,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"72IVNtZ1kGoS","outputId":"4be02f5d-1cd8-446b-c5fb-31e6ce710f4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: Adeel, \n"," Age: 20,\n","subject:nlp\n","HOW ARE YOU ADEEL!\n","how are you adeel!\n"]}],"source":["#Formatting: Formatting strings with placeholders.\n","name = \"Adeel\"\n","age = 20\n","subject='nlp'\n","text = \"Name: {}, \\n Age: {},\\nsubject:{}\".format(name,age,subject)\n","print(text)\n","\n","#Case Conversion: Converting the case of a string.\n","text = \"How are you Adeel!\"\n","upper_case = text.upper()\n","lower_case = text.lower()\n","print(upper_case)\n","print(lower_case)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1741066003288,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"Ry3TGS4YnlmT","outputId":"27e5dca4-7b40-45d2-bff7-294d13ae61a1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1741066105546,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"A_zgDJjUkdWi","outputId":"fe9ebd5e-7cc2-45c8-b4a8-100c533eb610"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"name":"stdout","output_type":"stream","text":["['This', 'is', 'a', 'sample', 'sentence', '.']\n"]}],"source":["import nltk\n","nltk.download('punkt_tab')\n","\n","from nltk.tokenize import word_tokenize\n","\n","text = \"This is a sample sentence.\"\n","tokens = word_tokenize(text)\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1741066178803,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"h0cUVC-8oWML","outputId":"4235ce2f-cfd2-49b7-f160-2ef62b097b48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Remove special characters from this text\n"]}],"source":["import re\n","text = \"Remove #special characters from this text!\"\n","filtered_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","print(filtered_text)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1741066204993,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"ftkvYW-Doelr","outputId":"4a4f809c-5a25-4353-d453-93690dd3eb24"},"outputs":[{"name":"stdout","output_type":"stream","text":["['123-456-7890']\n"]}],"source":["import re\n","text = \"Please call me at 123-456-7890.\"\n","phone_numbers = re.findall(r'\\d{3}-\\d{3}-\\d{4}', text)\n","print(phone_numbers)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OidQXh8loqgz","outputId":"04072618-0582-485b-c0ac-e263923d3d80","executionInfo":{"status":"ok","timestamp":1741670101700,"user_tz":-300,"elapsed":25,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}],"source":["from nltk.tokenize import word_tokenize\n","def is_english(text):\n","    try:\n","        words = word_tokenize(text)\n","        return all(word.isascii() for word in words)\n","    except UnicodeDecodeError:\n","      return False\n","text = \"This is English text.\"\n","print(is_english(text))\n","text = \"这是中文文本。\"\n","print(is_english(text))\n"]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","\n","def is_english(text):\n","  \"\"\"Checks if a text is likely to be English based on ASCII characters.\"\"\"\n","  if text.isascii():  # Check if the text is ASCII-compatible\n","    words = word_tokenize(text)\n","    return all(word.isascii() for word in words)\n","  else:\n","    return False  # If the text contains non-ASCII characters, it's not likely to be English\n","\n","# Example usage\n","text = \"This is English text.\"\n","print(is_english(text))  # Output: True\n","\n","text = \"这是中文文本。\"\n","print(is_english(text))  # Output: False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0Z2jG4UqMtt","executionInfo":{"status":"ok","timestamp":1741670636168,"user_tz":-300,"elapsed":9,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"7b58dd25-0b87-49ae-97f1-778ef592df25"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","\n","text = '\"This is نیچرل language processing تجربہ گاہ'\n","\n","# Tokenize the text into words\n","words = word_tokenize(text)\n","\n","# Filter out non-English words\n","english_words = [word for word in words if word.isascii()]\n","\n","# Join the English words to form the extracted text\n","english_text = ' '.join(english_words)\n","\n","print(english_text)  # Output: ''This is language processing''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ur5tlGj8rz3F","executionInfo":{"status":"ok","timestamp":1741671089864,"user_tz":-300,"elapsed":31,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"4dec06f5-b75c-4450-adb8-c54528043f9b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["`` This is language processing\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1741669711698,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"},"user_tz":-300},"id":"7P1JOGUGo4ck","outputId":"54617147-2f88-493b-8552-6ad8d6c61503"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['example', 'sentence', 'demonstrating', 'stop', 'word', 'removal', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('punkt_tab')  # Download the 'punkt' resource for tokenization.\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","text = \"This is an example sentence demonstrating stop word removal.\"\n","stop_words = set(stopwords.words('english'))\n","tokens = word_tokenize(text)\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n","print(filtered_tokens)"]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","ps = PorterStemmer()\n","words = [\"running\", \"easily\", \"better\"]\n","stemmed_words = [ps.stem(word) for word in words]\n","print(stemmed_words)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGOM2DgwmGzM","executionInfo":{"status":"ok","timestamp":1741669573327,"user_tz":-300,"elapsed":4767,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"e608ed61-2f3d-4dbe-8a1a-637d5a53e1e3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['run', 'easili', 'better']\n"]}]},{"cell_type":"code","source":["\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","word = \"reducing\"\n","lemma = lemmatizer.lemmatize(word,pos='v')\n","print(lemma)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHeGNLaOnK6c","executionInfo":{"status":"ok","timestamp":1741672505121,"user_tz":-300,"elapsed":20,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"607134fa-48bd-4a2c-e3ab-c24223f6f1c3"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["reduce\n"]}]},{"cell_type":"code","source":["\n","import unidecode\n","text = \"Àbout\"\n","normalized_text = unidecode.unidecode(text)\n","print(normalized_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZB-8vKPux_W","executionInfo":{"status":"ok","timestamp":1741672832175,"user_tz":-300,"elapsed":10,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"429e105b-976e-4cb4-9ef7-33d7224ce196"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["About\n"]}]},{"cell_type":"code","source":["text = \"I can't go to the party.\"\n","expanded_text = text.replace(\"can't\", \"cannot\")\n","print(expanded_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9QxUDOKwaCd","executionInfo":{"status":"ok","timestamp":1741672280838,"user_tz":-300,"elapsed":91,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"6b1cb07a-f52d-45bc-d6cc-454f900bd4c7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["I cannot go to the party.\n"]}]},{"cell_type":"code","source":["\n","from nltk.tokenize import word_tokenize\n","import string\n","\n","paragraph = \"This is a sample paragraph. It contains some punctuation marks, like commas, periods, and question marks!\"\n","\n","# Tokenize the paragraph into words\n","tokens = word_tokenize(paragraph)\n","\n","# Remove punctuation marks from the tokens\n","tokens_without_punctuation = [word for word in tokens if word not in string.punctuation]\n","\n","# Join the tokens back into a sentence\n","cleaned_text = ' '.join(tokens_without_punctuation)\n","\n","# Print the cleaned text\n","print(cleaned_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TLSJ0YSxxmV","executionInfo":{"status":"ok","timestamp":1741672689254,"user_tz":-300,"elapsed":35,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"8bc7969f-a672-4ac4-96ae-b7712f4ab557"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["This is a sample paragraph It contains some punctuation marks like commas periods and question marks\n"]}]},{"cell_type":"code","source":["import re\n","def filter_non_alphabetic(text):\n","    # Use regular expression to remove non-alphabetic characters\n","    filtered_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    return filtered_text\n","# Example usage\n","text = \"Remove #special characters from this text!\"\n","filtered_text = filter_non_alphabetic(text)\n","print(filtered_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsxaLJyCyJoG","executionInfo":{"status":"ok","timestamp":1741672739239,"user_tz":-300,"elapsed":7,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"5d8954ac-8b09-426f-fa1b-c27c9dad8a50"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Remove special characters from this text\n"]}]},{"cell_type":"code","source":["!pip install profanity-check\n","import joblib # Import joblib directly\n","import profanity_check\n","\n","#Adding this line to resolve the issue of deprecation\n","import sys\n","sys.modules['sklearn.externals.joblib'] = joblib\n","\n","def check_profanity(text):\n","    # Check if the text contains profanity directly using predict\n","    is_profane = any(profanity_check.predict([text]))\n","    return is_profane\n","\n","# Example usage\n","text = \"This is a clean text.\"\n","if check_profanity(text):\n","    print(\"The text contains profanity.\")\n","else:\n","    print(\"The text is clean.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":689},"id":"M42yGZkWy60K","executionInfo":{"status":"error","timestamp":1741673065108,"user_tz":-300,"elapsed":4591,"user":{"displayName":"Adeel Naeem","userId":"09880622680538190277"}},"outputId":"f2f467d7-76d1-4f9b-ef0c-abbd045db83f"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: profanity-check in /usr/local/lib/python3.11/dist-packages (1.0.3)\n","Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from profanity-check) (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (3.5.0)\n"]},{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'joblib' from 'sklearn.externals' (/usr/local/lib/python3.11/dist-packages/sklearn/externals/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-510acf352cef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install profanity-check'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;31m# Import joblib directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprofanity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Adding this line to resolve the issue of deprecation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/profanity_check/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprofanity_check\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1.0.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/profanity_check/profanity_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'profanity_check'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/vectorizer.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (/usr/local/lib/python3.11/dist-packages/sklearn/externals/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1Xo1sy30kxwWInOPsvsfV8dwLrfkITYWJ","authorship_tag":"ABX9TyMHzMMUCmdYiT8yFbj6e+3z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}