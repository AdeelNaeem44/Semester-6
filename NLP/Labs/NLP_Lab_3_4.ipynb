{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5RieHx-fbsB"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15528,
     "status": "ok",
     "timestamp": 1741064128655,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "D7rcqkrIgZxj",
    "outputId": "eacd0ff1-51d2-40ad-8791-ed16b78f8345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1741064434731,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "oALcX5IXglKC",
    "outputId": "ecac63a7-56f2-4347-ede1-6140cf4e6f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Adeel Naeem \n",
      "          Al-Awan Town New Chakra Rawalpindi \n",
      "                          +92-316-5659775 \n",
      "adeeln454@gmail.com, https://www.linkedin.com/in/adeel-naeem-952108267,  https://github.com/AdeelNaeem44                                 \n",
      " \n",
      " \n",
      " \n",
      "Seeking a Data Science Fellowship position to apply and enhance my skills in Programming Languages \n",
      " \n",
      "EXPERIENCE  \n",
      "Fresher \n",
      "                      \n",
      "EDUCATION  \n",
      "2022-BEYOND  \n",
      "BSAI, NUML ISLAMABAD  \n",
      "I’m doing Bachelor’s in AI and currently in 5th semester.  \n",
      "  \n",
      "2020-2022  \n",
      "INTERMEDIATE, PUNJAB GROUP OF COLLEGES   \n",
      "I passed my intermediate degree in FSC subjects with a grade ‘A+’.  \n",
      "  \n",
      " \n",
      "SKILLS  \n",
      " \n",
      "• \n",
      "SQL  \n",
      "  \n",
      "• \n",
      "Python  \n",
      "• \n",
      "C++  \n",
      "• \n",
      "Java \n",
      " \n",
      "ACTIVITIES  \n",
      "Myself Adeel Naeem. A Bachelor's student passionate about AI. Currently, I am a Student in Nation \n",
      "University of Modern Languages but now I want to move on some modern tech. So I choose Data \n",
      "Science as it’s also related with AI. In extra time, I play E-Games & cricket.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import fitz\n",
    "\n",
    "file_path='/content/drive/MyDrive/Adeel_resume.pdf'\n",
    "def extract_text_from_pdf(file_path):\n",
    "  doc=fitz.open(file_path)\n",
    "  text=''\n",
    "  for page in doc:\n",
    "    text+=page.get_text()\n",
    "  return text\n",
    "text=extract_text_from_pdf(file_path)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741065049336,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "faN8HH02hxga",
    "outputId": "d4906543-215f-434f-87e8-9c945ca5ec88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "sample\n",
      "13\n",
      "['This', 'is', 'a', 'sentence.']\n",
      "This is a sentence.\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Hello\"\n",
    "str2 = \"world\"\n",
    "result = str1 + \" \" + str2\n",
    "print(result)\n",
    "\n",
    "#Substring: Extracting a part of a string.\n",
    "text = \"This is a sample text.\"\n",
    "substring = text[10:16]\n",
    "print(substring)\n",
    "\n",
    "#Length: Getting the length of a string.\n",
    "text = \"Hello, world!\"\n",
    "length = len(text)\n",
    "print(length)\n",
    "\n",
    "#Splitting: Splitting a string into a list of substrings.\n",
    "text = \"This is a sentence.\"\n",
    "words = text.split()\n",
    "print(words)\n",
    "\n",
    "#Joining: Joining a list of strings into a single string.\n",
    "words = ['This', 'is', 'a', 'sentence.']\n",
    "text = ' '.join(words)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741065504500,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "72IVNtZ1kGoS",
    "outputId": "4be02f5d-1cd8-446b-c5fb-31e6ce710f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Adeel, \n",
      " Age: 20,\n",
      "subject:nlp\n",
      "HOW ARE YOU ADEEL!\n",
      "how are you adeel!\n"
     ]
    }
   ],
   "source": [
    "#Formatting: Formatting strings with placeholders.\n",
    "name = \"Adeel\"\n",
    "age = 20\n",
    "subject='nlp'\n",
    "text = \"Name: {}, \\n Age: {},\\nsubject:{}\".format(name,age,subject)\n",
    "print(text)\n",
    "\n",
    "#Case Conversion: Converting the case of a string.\n",
    "text = \"How are you Adeel!\"\n",
    "upper_case = text.upper()\n",
    "lower_case = text.lower()\n",
    "print(upper_case)\n",
    "print(lower_case)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741066003288,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "Ry3TGS4YnlmT",
    "outputId": "27e5dca4-7b40-45d2-bff7-294d13ae61a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1741066105546,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "A_zgDJjUkdWi",
    "outputId": "fe9ebd5e-7cc2-45c8-b4a8-100c533eb610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is a sample sentence.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741066178803,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "h0cUVC-8oWML",
    "outputId": "4235ce2f-cfd2-49b7-f160-2ef62b097b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove special characters from this text\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Remove #special characters from this text!\"\n",
    "filtered_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "print(filtered_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1741066204993,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "ftkvYW-Doelr",
    "outputId": "4a4f809c-5a25-4353-d453-93690dd3eb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-456-7890']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Please call me at 123-456-7890.\"\n",
    "phone_numbers = re.findall(r'\\d{3}-\\d{3}-\\d{4}', text)\n",
    "print(phone_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1741670101700,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "OidQXh8loqgz",
    "outputId": "04072618-0582-485b-c0ac-e263923d3d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def is_english(text):\n",
    "    try:\n",
    "        words = word_tokenize(text)\n",
    "        return all(word.isascii() for word in words)\n",
    "    except UnicodeDecodeError:\n",
    "      return False\n",
    "text = \"This is English text.\"\n",
    "print(is_english(text))\n",
    "text = \"这是中文文本。\"\n",
    "print(is_english(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741670636168,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "M0Z2jG4UqMtt",
    "outputId": "7b58dd25-0b87-49ae-97f1-778ef592df25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def is_english(text):\n",
    "  \"\"\"Checks if a text is likely to be English based on ASCII characters.\"\"\"\n",
    "  if text.isascii():  # Check if the text is ASCII-compatible\n",
    "    words = word_tokenize(text)\n",
    "    return all(word.isascii() for word in words)\n",
    "  else:\n",
    "    return False  # If the text contains non-ASCII characters, it's not likely to be English\n",
    "\n",
    "# Example usage\n",
    "text = \"This is English text.\"\n",
    "print(is_english(text))  # Output: True\n",
    "\n",
    "text = \"这是中文文本。\"\n",
    "print(is_english(text))  # Output: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741671089864,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "Ur5tlGj8rz3F",
    "outputId": "4dec06f5-b75c-4450-adb8-c54528043f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` This is language processing\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = '\"This is نیچرل language processing تجربہ گاہ'\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Filter out non-English words\n",
    "english_words = [word for word in words if word.isascii()]\n",
    "\n",
    "# Join the English words to form the extracted text\n",
    "english_text = ' '.join(english_words)\n",
    "\n",
    "print(english_text)  # Output: ''This is language processing''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1741669711698,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "7P1JOGUGo4ck",
    "outputId": "54617147-2f88-493b-8552-6ad8d6c61503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'demonstrating', 'stop', 'word', 'removal', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')  # Download the 'punkt' resource for tokenization.\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is an example sentence demonstrating stop word removal.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(text)\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4767,
     "status": "ok",
     "timestamp": 1741669573327,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "iGOM2DgwmGzM",
    "outputId": "e608ed61-2f3d-4dbe-8a1a-637d5a53e1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'easili', 'better']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()\n",
    "words = [\"running\", \"easily\", \"better\"]\n",
    "stemmed_words = [ps.stem(word) for word in words]\n",
    "print(stemmed_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1741672505121,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "AHeGNLaOnK6c",
    "outputId": "607134fa-48bd-4a2c-e3ab-c24223f6f1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = \"reducing\"\n",
    "lemma = lemmatizer.lemmatize(word,pos='v')\n",
    "print(lemma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741672832175,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "pZB-8vKPux_W",
    "outputId": "429e105b-976e-4cb4-9ef7-33d7224ce196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import unidecode\n",
    "text = \"Àbout\"\n",
    "normalized_text = unidecode.unidecode(text)\n",
    "print(normalized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1741672280838,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "I9QxUDOKwaCd",
    "outputId": "6b1cb07a-f52d-45bc-d6cc-454f900bd4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot go to the party.\n"
     ]
    }
   ],
   "source": [
    "text = \"I can't go to the party.\"\n",
    "expanded_text = text.replace(\"can't\", \"cannot\")\n",
    "print(expanded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1741672689254,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "_TLSJ0YSxxmV",
    "outputId": "8bc7969f-a672-4ac4-96ae-b7712f4ab557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample paragraph It contains some punctuation marks like commas periods and question marks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "paragraph = \"This is a sample paragraph. It contains some punctuation marks, like commas, periods, and question marks!\"\n",
    "\n",
    "# Tokenize the paragraph into words\n",
    "tokens = word_tokenize(paragraph)\n",
    "\n",
    "# Remove punctuation marks from the tokens\n",
    "tokens_without_punctuation = [word for word in tokens if word not in string.punctuation]\n",
    "\n",
    "# Join the tokens back into a sentence\n",
    "cleaned_text = ' '.join(tokens_without_punctuation)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741672739239,
     "user": {
      "displayName": "Adeel Naeem",
      "userId": "09880622680538190277"
     },
     "user_tz": -300
    },
    "id": "FsxaLJyCyJoG",
    "outputId": "5d8954ac-8b09-426f-fa1b-c27c9dad8a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove special characters from this text\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def filter_non_alphabetic(text):\n",
    "    # Use regular expression to remove non-alphabetic characters\n",
    "    filtered_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return filtered_text\n",
    "# Example usage\n",
    "text = \"Remove #special characters from this text!\"\n",
    "filtered_text = filter_non_alphabetic(text)\n",
    "print(filtered_text)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMHzMMUCmdYiT8yFbj6e+3z",
   "mount_file_id": "1Xo1sy30kxwWInOPsvsfV8dwLrfkITYWJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
